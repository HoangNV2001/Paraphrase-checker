{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96579231",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5de4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from Modules.SimilarityMeasures import vectorize_pair\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedc0c1",
   "metadata": {},
   "source": [
    "# Preprocess the VnPara dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bd9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(dir):\n",
    "    text_set =[]\n",
    "    with open(dir, 'r', encoding ='utf-8') as text:\n",
    "        for line in text.readlines():\n",
    "            text_set.append(line.strip())\n",
    "    return text_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffacc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(sentence, keep_under_score):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'(v\\s\\.\\sv\\s.)', '', sentence, re.UNICODE)\n",
    "    if keep_under_score:\n",
    "        sub_string = ''.join(ch for ch in sentence if (ch.isalnum() or ch == ' ' or ch == '_'))\n",
    "    else:\n",
    "        sub_string = ''.join(ch for ch in sentence if (ch.isalnum() or ch == ' '))\n",
    "    sub_string_2 = re.sub('\\s{2,}', ' ', sub_string, re.UNICODE)\n",
    "    return sub_string_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0436411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_pair(sentences1, sentences2, keep_under_score = True):\n",
    "    number_sentences = len(sentences1)\n",
    "    list_sentences = []\n",
    "    for i in range(number_sentences):\n",
    "        s1 = remove_special_chars(sentences1[i], keep_under_score)\n",
    "        s2 = remove_special_chars(sentences2[i], keep_under_score)\n",
    "        s = {'s1': s1, 's2': s2}\n",
    "        list_sentences.append(s)\n",
    "    return list_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76889faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = read_data_file('Data//vnPara//Labels.txt')\n",
    "for i in range (len(train_labels)):\n",
    "    if train_labels[i] == '1,':\n",
    "        train_labels[i] = 1\n",
    "    else:\n",
    "        train_labels[i] = int(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1c55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "list_sentence_1 = []\n",
    "list_sentence_2 = []\n",
    "\n",
    "with open(\"Data//vnPara//Sentences1.txt\", encoding ='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_1.append(line)\n",
    "\n",
    "with open(\"Data//vnPara//Sentences2.txt\", encoding ='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        list_sentence_2.append(line)\n",
    "\n",
    "pairs = create_list_pair(list_sentence_1, list_sentence_2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1297499",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(train_labels)\n",
    "for i in range(num_samples):\n",
    "    s1 = pairs[i]['s1'].split()\n",
    "    s2 = pairs[i]['s2'].split()\n",
    "    train_data.append(vectorize_pair(s1,s2))\n",
    "\n",
    "X = np.array(train_data)\n",
    "y = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487360b",
   "metadata": {},
   "source": [
    "# K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5af7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9643435980551054 0.9667673716012085\n",
      "0.9854132901134521 0.9850746268656716\n",
      "0.9773095623987034 0.9774193548387097\n",
      "0.9707792207792207 0.9713375796178344\n",
      "0.9691558441558441 0.9691056910569106\n",
      "Average 5-fold accuracy: 0.9734003031004651\n",
      "Average 5-fold f1: 0.9739409247960669\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "f1_list = []\n",
    "acc_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    svm_clf= SVC(kernel = 'rbf', probability = True)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "\n",
    "    f1 = f1_score(y_test, svm_clf.predict(X_test))\n",
    "    f1_list.append(f1)\n",
    "    acc = accuracy_score(y_test, svm_clf.predict(X_test))\n",
    "    acc_list.append(acc)\n",
    "    print(acc,f1)\n",
    "\n",
    "print(\"Average 5-fold accuracy:\", sum(acc_list)/len(acc_list))\n",
    "print(\"Average 5-fold f1:\", sum(f1_list)/len(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77aaf4a",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f29ef8",
   "metadata": {},
   "source": [
    "Train the final model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae56ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy: 0.9691558441558441\n",
      "Final model f1: 0.9737851662404091\n"
     ]
    }
   ],
   "source": [
    "svm_clf= SVC(kernel = 'rbf', probability = True)\n",
    "svm_clf.fit(X, y)\n",
    "\n",
    "print(\"Final model accuracy:\", accuracy_score(y_test, svm_clf.predict(X_test)))\n",
    "print(\"Final model f1:\", f1_score(y, svm_clf.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fc072",
   "metadata": {},
   "source": [
    "Save the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe88f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Models//SVM//svm_paraphrase_identification_model.sav'\n",
    "pickle.dump(svm_clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
